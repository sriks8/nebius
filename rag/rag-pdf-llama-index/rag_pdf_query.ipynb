{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOuPGNLs0Rzh"
      },
      "source": [
        "# Query PDF documents using RAG (Llama-Index + Nebius AI)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nebius/token-factory-cookbook/blob/main/rag/rag-pdf-llama-index/rag_pdf_query.ipynb)\n",
        "[![](https://img.shields.io/badge/Powered%20by-Nebius%20AI-orange?style=flat&labelColor=orange&color=green)](http://tokenfactory.nebius.com/)\n",
        "\n",
        "This example shows querying a PDF using  [llama index](https://docs.llamaindex.ai/en/stable/) framework and running LLM on [Nebius Token Factory](https://tokenfactory.nebius.com/)\n",
        "\n",
        "[Read more about it here](https://github.com/nebius/token-factory-cookbook/blob/main/rag/rag-pdf-llama-index/README.md)\n",
        "\n",
        "\n",
        "## References and Acknowledgements\n",
        "\n",
        "- [llamaindex documentation](https://docs.llamaindex.ai/en/stable/)\n",
        "- [Nebius Token Factory](https://tokenfactory.nebius.com/)\n",
        "- [Nebius Token Factory documentation](https://docs.tokenfactory.nebius.com//inference/quickstart)\n",
        "\n",
        "## Pre requisites\n",
        "\n",
        "- Nebius API key.  Sign up for free at [Token Factory](https://tokenfactory.nebius.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idu8ref1XEri"
      },
      "source": [
        "## 2 - Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBn7wla7YeVl",
        "outputId": "b8b04890-e974-4a5d-b47f-3c0b117fbede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   RUNNING_ON_COLAB = True\n",
        "   print(\"Running in Colab\")\n",
        "else:\n",
        "  RUNNING_ON_COLAB = False\n",
        "  print(\"NOT Running in Colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WdH7Q0uNXJ3u",
        "outputId": "eb9966e8-dd89-416a-ff59-d133fa01bf2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/329.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/329.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if RUNNING_ON_COLAB:\n",
        "  # Install the required packages\n",
        "  !pip install -q llama-index-llms-litellm \\\n",
        "                  jedi \\\n",
        "                  llama-index-readers-file \\\n",
        "                  llama-index-llms-nebius \\\n",
        "                  llama-index-embeddings-nebius \\\n",
        "                  llama-index-embeddings-huggingface \\\n",
        "                  python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHr1sLWuX7e3"
      },
      "source": [
        "## 3 - Load Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk4FU9keX8L6",
        "outputId": "6aed0cd1-7d5b-4452-fbcf-63f1b7911ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NEBIUS_API_KEY found\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "## Recommended way of getting configuration\n",
        "if RUNNING_ON_COLAB:\n",
        "   from google.colab import userdata\n",
        "   NEBIUS_API_KEY = userdata.get('NEBIUS_API_KEY')\n",
        "else:\n",
        "   from dotenv import load_dotenv\n",
        "   load_dotenv()\n",
        "   NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY')\n",
        "\n",
        "\n",
        "## quick hack (not recommended) - you can hardcode the config key here\n",
        "# NEBIUS_API_KEY = \"your_key_here\"\n",
        "\n",
        "if NEBIUS_API_KEY:\n",
        "  print ('✅ NEBIUS_API_KEY found')\n",
        "  os.environ['NEBIUS_API_KEY'] = NEBIUS_API_KEY\n",
        "else:\n",
        "  raise RuntimeError ('❌ NEBIUS_API_KEY NOT found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nI0FzILYVQ-"
      },
      "source": [
        "## 4 - Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Xdc6njBCYXo_",
        "outputId": "85a0ecef-321f-4c83-b1f2-de81ef8ee969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-02 00:15:48--  https://github.com/sriks8/nebius/raw/main/attn.pdf\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sriks8/nebius/main/attn.pdf [following]\n",
            "--2026-02-02 00:15:49--  https://raw.githubusercontent.com/sriks8/nebius/main/attn.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2215244 (2.1M) [application/octet-stream]\n",
            "Saving to: ‘data/attention.pdf’\n",
            "\n",
            "data/attention.pdf  100%[===================>]   2.11M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2026-02-02 00:15:49 (31.0 MB/s) - ‘data/attention.pdf’ saved [2215244/2215244]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "input_dir = 'data'\n",
        "\n",
        "if RUNNING_ON_COLAB:\n",
        "    shutil.os.makedirs(input_dir, exist_ok=True)\n",
        "    !wget -O  '{input_dir}/attention.pdf' 'https://github.com/sriks8/nebius/raw/main/attn.pdf'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pNQ2ozxgooz"
      },
      "source": [
        "## 5 - Setup Embedding Model\n",
        "\n",
        "We have a choice of local embedding model (fast) or running it on the cloud\n",
        "\n",
        "If running locally:\n",
        "- choose smaller models\n",
        "- less accuracy but faster\n",
        "\n",
        "If running on the cloud\n",
        "- We can run large models (billions of params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UBOBBKorgvTb"
      },
      "outputs": [],
      "source": [
        "## Local model\n",
        "import os\n",
        "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
        "\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "## Running embedding models on Nebius cloud\n",
        "# from llama_index.embeddings.nebius import NebiusEmbedding\n",
        "# Settings.embed_model = NebiusEmbedding(\n",
        "#                         model_name='BAAI/bge-en-icl',\n",
        "#                         api_key=os.getenv(\"NEBIUS_API_KEY\") # if not specfified here, it will get taken from env variable\n",
        "#                        )\n",
        "\n",
        "## Try out a few open source embedding models locally\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    # model_name = 'sentence-transformers/all-MiniLM-L6-v2' # 23 M params\n",
        "    model_name = 'BAAI/bge-small-en-v1.5'  # 33M params\n",
        "    # model_name = 'Qwen/Qwen3-Embedding-0.6B'  # 600M params\n",
        "    # model_name = 'BAAI/bge-en-icl'  # 7B params\n",
        "    #model_name = 'intfloat/multilingual-e5-large-instruct'  # 560M params\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lKdlYukZ2h_"
      },
      "source": [
        "## 6 - Setup LLama Index with Nebius\n",
        "\n",
        "We can use `llama_index.llms.nebius.NebiusLLM` or `llama_index.llms.litellm.LiteLLM`.\n",
        "\n",
        "See examples below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Fm5YUtNHaPNY"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.nebius import NebiusLLM\n",
        "from llama_index.llms.litellm import LiteLLM\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = NebiusLLM(\n",
        "                model='meta-llama/Llama-3.3-70B-Instruct',\n",
        "                # model='deepseek-ai/DeepSeek-R1-0528',\n",
        "                # model='openai/gpt-oss-20b',\n",
        "                api_key=os.getenv(\"NEBIUS_API_KEY\") # if not specfified, it will get taken from env variable\n",
        "    )\n",
        "\n",
        "# Settings.llm = LiteLLM(\n",
        "#                 model='nebius/meta-llama/Llama-3.3-70B-Instruct',\n",
        "#                 model='nebius/deepseek-ai/DeepSeek-R1-0528',\n",
        "#                 model='nebius/openai/gpt-oss-20b',\n",
        "#                 api_key=os.getenv(\"NEBIUS_API_KEY\") # if not specfified, it will get taken from env variable\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIsbPCkCbh6G"
      },
      "source": [
        "## 6 - Read PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wyVEm2Q4cGAM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "pattern = os.path.join(input_dir, '*.pdf')\n",
        "input_file_count = len(glob.glob(pattern, recursive=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ9FHpUvblJ9",
        "outputId": "25cce29c-efe0-443f-b8b6-155a1b208296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 15 docs from 1 files\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(input_dir).load_data()\n",
        "print (f'Loaded {len(documents)} docs from {input_file_count} files')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yiF4PBdrdH8R",
        "outputId": "7e35af38-c758-490d-c8f6-18487c4c9432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.13 s, sys: 398 ms, total: 9.53 s\n",
            "Wall time: 9.63 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSic2nxNkpCn"
      },
      "source": [
        "##  7 - Query documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "27Xi4E-mksRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c430c8e-083a-458f-c9cc-6a4100854a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The attention mechanism is a technique used to focus on specific parts of the input data that are relevant for a particular task, rather than considering the entire input equally. It is often used in deep learning models, particularly in natural language processing and computer vision tasks. The attention mechanism allows the model to weigh the importance of different input elements, such as words or pixels, and allocate more attention to the elements that are most relevant for the task at hand. This is typically achieved through a set of attention weights, which are learned during training and are used to compute a weighted sum of the input elements. The attention mechanism can be used to model complex dependencies and relationships between different parts of the input data, and has been shown to be effective in a wide range of applications.\n"
          ]
        }
      ],
      "source": [
        "response = index.as_query_engine().query(\"What is attention mechanism?\")\n",
        "print (response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmKZ73RcqHrk",
        "outputId": "e2f1bdfb-7068-49d3-d93e-45972ced7896"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'31b40151-7d77-440a-91e3-5911a070dff9': {'file_path': '/home/sujee/my-stuff/projects/nebius/token-factory-cookbook-1/rag/rag-pdf-llama-index/data/attention.pdf',\n",
              "  'file_name': 'attention.pdf',\n",
              "  'file_type': 'application/pdf',\n",
              "  'file_size': 2215244,\n",
              "  'creation_date': '2025-07-07',\n",
              "  'last_modified_date': '2025-07-07'},\n",
              " '0409e07f-8930-4a01-806d-b94ce9301994': {'file_path': '/home/sujee/my-stuff/projects/nebius/token-factory-cookbook-1/rag/rag-pdf-llama-index/data/attention.pdf',\n",
              "  'file_name': 'attention.pdf',\n",
              "  'file_type': 'application/pdf',\n",
              "  'file_size': 2215244,\n",
              "  'creation_date': '2025-07-07',\n",
              "  'last_modified_date': '2025-07-07'}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# see where the answer came from\n",
        "response.metadata"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag-pdf-llama-index",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}